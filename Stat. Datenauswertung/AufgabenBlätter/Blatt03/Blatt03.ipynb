{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Rechnernutzung in der Physik  \n",
    "\n",
    "**Institut für Experimentelle Teilchenphysik**  \n",
    "Prof. G. Quast \n",
    "Dr. Th. Chwalek  \n",
    "WS 2024/25 – Blatt 03  \n",
    "Besprechung: Montag 2.12/ Dienstag 3.12. bzw. Montag 9.12./ Dienstag 10.12.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Info-Veranstaltung zur Projektentwicklung Physik am 29.11.\n",
    "---\n",
    "\n",
    "Die Bereichsleitung BL5 organisiert am 29.11. um 16.00 Uhr im Gaede-HS eine große Informationsveranstaltung zur Projektentwicklung Physik. Dabei sollen von der Abteilung Planen und Bau die aktuellen Planungen zur baulichen Weiterentwicklung unserer Fakultät vorgestellt werden. Im Anschluss daran besteht die Möglichkeit, dies mit den drei anwesenden KIT-Präsidiumsmitgliedern Präsident Hesthaven, Vizepräsident Kraft und Vizepräsident Schwartze zu diskutieren. \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf dem dritten Übungsblatt gibt es zunächst eine Anwendung der Monte-Carlo-Methode zur Untersuchung der Poisson-Veteilung.\n",
    "Anschließend beschäftigen Sie sich mit einem der wichtigsten Grundbegriffe der modernen Parameteranpassung - der Maximum-Likelihood-Methode.  \n",
    "Sie haben mit großer Wahrscheinlichkeit im Laufe Ihres Studiums oder Privatlebens bereits die Maximum-Likelihood-Methode (oder ihre Abwandlungen) verwendet, um die Steigung einer Geraden oder andere Parameter einer Messung zu bestimmen. Mit diesem Übungsblatt beschäftigen Sie sich noch mal ganz genau mit der Methodik und nehmen hoffentlich mit, auf welchem Prinzip die unterschiedlichen eingebauten Fitfunktionen in *SciPy*, *kafe2*, *probfit* und vielen mehr (ja, auch Excel) aufgebaut sind. Sie werden merken, dass sich hinter all den angesprochenen Methoden keine schwarze Magie befindet, sondern die Umsetzung und Überführung auf eigene Programme ganz einfach ist. Mit einem guten Verständis der Maximum-Likelihood-Methode können Sie dann nicht nur die Methode der kleinsten Quadrate verstehen, sondern auch schon bald Anpassungen wie diese selbst durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Aufgabe 1: Simulation eines Poisson-Prozesses <a id=\"Aufgabe1\"></a>\n",
    "---\n",
    "\n",
    "In dieser Aufgabe soll eine Folge von Zeitpunkten erzeugt werden, zu denen ein Ereignis stattfindet; \n",
    "die Eintreffwahrscheinlichkeit pro Zeitintervall ist dabei konstant, d.h. der Prozess findet mit einer \n",
    "festen mittleren Rate statt. Solche Prozesse sind in der Physik sehr häufig, z.B. das Eintreffen eines\n",
    "quantenmechanischen Ereignisses wie die Abstrahlung eines Photons durch ein angeregtes Atom oder \n",
    "Zerfälle von Kernen oder Teilchen oder die Zeitpunkte der Erzeugung von Teilchen in einem \n",
    "Teilchenbeschleuniger wie dem Large-Hadron-Collider. \n",
    "\n",
    "Für die Simulation von Experimenten zur Untersuchung von Poisson-Prozessen ist der Zeitpunkt des \n",
    "Ereignisses entscheidend, weil praktisch alle Sensoren zum Nachweis nach einem Ereignis für eine \n",
    "gewisse Zeit vollständig oder teilweise ineffizient sind oder ungenaue Ergebnisse liefern. \n",
    "Wenn z.B. ein elektrischer Puls einer bestimmten Dauer ausgelöst wird, dann kann kein zweiter \n",
    "Puls direkt anschließend fehlerfrei detektiert werden, weil es zu einer Überlagerung kommt. \n",
    "\n",
    "In dieser Studie soll zunächst eine Reihe von Zeitpnkten simuliert werden, zu denen Ereignisse \n",
    "stattgefunden haben.  Die Voraussetzung einer konstanten Eintreffwahrscheinlichkeit führt  \n",
    "zu einer Poisson-Verteilung der in festen Zeitintervallen eintreffenden Ereignisse, wie \n",
    "im Dokument [Poisson.pdf](Poisson.pdf) illustriert wird.  \n",
    "\n",
    "Nach einer Überprüfung der erwarteten statistischen Eigenschaften der erzeugten Zeitpunkte\n",
    "wenden wir sie zur Bestimmung der Nachweiseffizienz und Korrektur für einen einfachen\n",
    "Detektor an. \n",
    "\n",
    "\n",
    "## a) Verteilung der Wartezeiten\n",
    "\n",
    "Zur Lösung der gestellen Aufgabe gehen wir zunächst von der Verteilung der sogenannten \"Wartezeit\" \n",
    "aus, d.h. der zwischen dem Auftreten von zwei Zufallsereignissen verstrichenen Zeit.\n",
    "\n",
    "Die Verteilungsdichte der Wartezeiten, $t_w$, zwischen zwei\n",
    "Ereignissen, die in der Zeit gleichverteilt sind, ist gegeben durch\n",
    "$f(t_w)=\\frac{1}{\\overline{t_w}} \\exp{(-t_w/\\overline{t_w})}\\,$, wobei\n",
    "$\\overline{t_w}$ die mittlere Wartezeit ist und dem Kehrwert der\n",
    "Ereignisrate $R$ entspricht. Also gilt auch $f(t_w)=R \\cdot \\exp{(- R\\,t_w)}$\n",
    "\n",
    "  > **Herleitung: Verteilung der Wartezeiten**  \n",
    "    Man denke sich die Zeit $t_w$ in $n$ kleine, gleich große Intervalle\n",
    "    $\\Delta t_i=t_w/n$ zerlegt. Die Wahrscheinlichkeit, ein Ereignis in\n",
    "    einem solchen Intervall zu beobachten, ist gegeben durch\n",
    "    $p=R\\,t_w\\,/n$. Ein Zerfall nach der Zeit $t_w$ bedeutet, dass in den\n",
    "    Intervallen davor kein Ereignis beobachtet wurde, d.h.\n",
    "    $p(t_w) = (1 - \\, Rt_w/n)^n$, für $n \\to\\infty$ also $p(t_w) =\\exp(-Rt_w)$.\n",
    "\n",
    "\n",
    "Nutzen Sie diese Verteilung der Wartezeiten und schreiben Sie eine\n",
    "Funktion, die, ausgehend von $t_0=0$, eine Folge von $N$=50'000\n",
    "Zeitpunkten $t_i$ bestimmt, zu denen solche Ereignisse auftreten. Der\n",
    "Einfachheit halber sei die Rate $R$\\,=\\,1/Zeiteinheit (ZE). \n",
    "\n",
    "Histogrammieren Sie zur Kontrolle die Zeiten zwischen\n",
    "aufeinanderfolgenden Ereignissen und überlagern Sie zur Kontrolle \n",
    "die Exponentialfunktion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als kleine Erleichterung hier einige Funktionen aus den Vorlesungsbeispielen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and helper functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "\n",
    "\n",
    "## Poisson-Verteilung aus Vorlesungsbeispielen\n",
    "# ---------------------------------------\n",
    "# Poisson distribution\n",
    "def fPoisson(x, mu):\n",
    "    k = np.around(x)\n",
    "    #  return (mu**k)/np.exp(mu)/sp.gamma(k+1.)\n",
    "    return np.exp(k * np.log(mu) - mu - sp.gammaln(k + 1.0))  # numerically more robust\n",
    "\n",
    "\n",
    "## Funktion aus PhyPraKit\n",
    "# ---------------------------------------\n",
    "def histstat(binc, bine, pr=True):\n",
    "    # calculate mean and standard deviation of a histogram \n",
    "    #  with bincontents binc and bin edges bine\n",
    "    bincent = (bine[1:] + bine[:-1]) / 2  # determine bincenters\n",
    "    mean = sum(binc * bincent) / sum(binc)\n",
    "    rms = np.sqrt(sum(binc * bincent**2) / sum(binc) - mean**2)\n",
    "    if pr:\n",
    "        print('hist statistics:\\n' '   mean=%g, sigma=%g\\n' % (mean, rms))\n",
    "    return mean, rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Code zur Erzeugung der Zeitpunkte\n",
    "\n",
    "Nevents = 50000\n",
    "data = np.zeros(Nevents)\n",
    "dT = 1.0  # mean time between signal events\n",
    "\n",
    "# generate event times (signal)\n",
    "\n",
    "# ->>\n",
    "\n",
    "# plot time between events\n",
    "\n",
    "# ->> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Statistische Auswertung\n",
    "\n",
    "(1) Histogrammieren Sie die Häufigkeit von Ereignissen in festen Zeitintervallen, d.h. \n",
    "stellen Sie die zeitliche Verteilung der Ereigniszeipunkte in einem Histogramm mit\n",
    "500 Bins dar. \n",
    " \n",
    "Welche Verteilung erhalten Sie? Welche Ereignisrate/Bin lesen Sie ab? Zeichen Sie \n",
    "auch die erwartete mittlere Rate ein. \n",
    "\n",
    "(2) Sellen Sie nun die Anzahlen der in den 500 Intervallen beobachteten Ereignisse,\n",
    "d.h. die Bin-Inhalte aus (1), als Häufikeitsverteilung dar und überlagern Sie zum \n",
    "Vergleich die Poission-Verteilung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statistical analysis\n",
    "\n",
    "# (1) plot event rate in 500 bins\n",
    "tbins = 500\n",
    "\n",
    "# also show expectation value on graph\n",
    "\n",
    "# (2) plot distribution of event counts per bin\n",
    "\n",
    "# \n",
    "print('\\n *==* Results PoissonProcess:')\n",
    "print('Statistik der Ereignishäufigkeiten')\n",
    "print(f'   mean of counts per bin: ???')\n",
    "print(f'       standard deviation: ???')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Anwendung: Totzeitkorrektur für einen Detektor\n",
    "\n",
    "Als Anwendung unserer kleinen Experimentsimulation soll nun das Ansprechverhalten eines\n",
    "Detektors und dessen Einfluss auf die gemessene Ereignisrate beschrieben werden.\n",
    "\n",
    "Nehmen wir dazu an, ein Detektor habe nach dem Registrieren eines Ereignisses zum Zeitpunkt $t_i$ \n",
    "eine Totzeit, die dazu führt, dass die Nachweiseffizienz nach der Funktion \u000f\n",
    " $\\epsilon(t) = 5./ZE · (t − t_i )$ für $(t − ti ) < 0.2 ZE$ \n",
    "von Null bis Eins ansteigt. Welche Ereignisrate misst der Detektor? Wie groß\n",
    "ist der auf Grund der Totzeit notwendige Korrekturfaktor auf die gemessene Rate?\n",
    "\n",
    " >  **Hinweis** \n",
    "    Der Code zur Detektorsimulation benötigt ein \"Gedächtnis\", nämlich den Zeitpunkt\n",
    "    des letzten registrierten Ereignisses. Dazu empfiehlt sich die Implementierung\n",
    "    als Klasse, wie im folgenden Codeabschnitt gezeigt: \n",
    "\n",
    "    ```python\n",
    "    # Class defining detector properties\n",
    "    class SimpleDetector:\n",
    "    \"\"\"a class defining a simple detector with dead time\"\"\"\n",
    "\n",
    "    def __init__(self, tau=0.2):\n",
    "    self.tlast = -1.\n",
    "    # initialize variable storing argument of last call\n",
    "    self.tfulleff = tau # time after which full efficiency is regained\n",
    "\n",
    "    def Efficiency(self, dt):\n",
    "    # function defining detector characteristics,\n",
    "    #\n",
    "    # ->  here the efficiency depending on time since last hit\n",
    "    # ...\n",
    "    return eff\n",
    "\n",
    "    def Signal(self,t):\n",
    "    # function returning True if signal at time t is detected\n",
    "    #\n",
    "    random sampling of function \"Efficiency()\"\n",
    "    # ...\n",
    "    #SigSeen = ... # True/False\n",
    "    return SigSeen\n",
    "    ```\n",
    "    Eine Instanz der Klasse kann dann alle notwendigen Daten zum simulierten Detektor und zur\n",
    "    Berechnung der Nachweiseffizienz speichern und die benötigten Funktionen bereit stellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeriung der Klasse zur Beschreibung des Detektors \n",
    "\n",
    "# Class defining detector properties\n",
    "class SimpleDetector:\n",
    "    \"\"\"a class defining a simple detector with dead time\"\"\"\n",
    "\n",
    "# ->>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Totzeitbestimmung\n",
    "\n",
    "# ->>\n",
    "\n",
    "# print result:\n",
    "print( 'Detector efficiency study:')\n",
    "print( '  - events detected %i of %i , ' %(Nseen, Ndat ) )\n",
    "print( '  - event rate %g, measured rate %g' %(Ndat/T, Nseen/T) )\n",
    "print( '      ==> efficiency correction factor: %g' %(EffCorr) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Aufgabe 2: Poisson-Likelihood <a id=\"Aufgabe2\"></a>\n",
    "---\n",
    "\n",
    "In der ersten Aufgabe beschäftigen Sie sich mit einem vermutlich bereits bekanntem Beispiel aus dem Praktikum: Sie haben eine radioaktive Quelle erhalten und messen elektronisch die Klicks eines Geiger-Müller-Zählrohrs in aufeinanderfolgenden, gleich langen Zeitintervallen. Die Messdaten haben Sie in der Datei *Geiger_Zaehler.txt* abgespeichert und wollen nun für die weitere Auswertung die Anzahl der radioaktiven Zerfälle pro Zeitintervall bestimmen. \n",
    "\n",
    "Bei der Auswertung der Daten erinnern Sie sich an die Vorlesung *Rechnernutzung* und die Parameterschätzung mithilfe der Maximum-Likelihood-Methode und beschließen, statt *kafe2* zu nutzen, die gesuchte Zahl selbst abzuschätzen. Sie schauen zurück in die Folien der Vorlesung und entdecken die Funktion\n",
    "\n",
    "$$ \n",
    "L\\left(\\left\\{x_i\\right\\}|a\\right)=\\prod_{i\\leq n}f\\left(x_i,a\\right).\n",
    "$$\n",
    "\n",
    "Sie erinnern sich daran, dass $\\left\\{x_i\\right\\}$ ihre Messungen sind, $f(x,a)$ die zugrunde liegende Wahrscheinlichkeitsdichte und $a$ der gesuchte Parameter ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Likelihoodfunktion\n",
    "\n",
    "Im ersten Aufgabenteil überprüfen Sie graphisch die Form der Likelihoodfunktion.\n",
    "> Frage: Warum ist es gerechtfertig die Poissonverteilung als zugrunde liegende Wahrscheinlichkeitsdichte für den Ausgang des Zählexperiments zu wählen? Welche Abweichungen von der Annahme gibt es beim Aufbau und der Messung?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "->> Antwort:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie die Likelihoodfunktion $L\\left(\\left\\{x_i\\right\\}|a\\right)$. Es bietet sich an, die Wahrscheinlichkeitsdichte als Argument der Funktion zu übergeben. Denken Sie daran, dass Sie einen gewissen Parameterereich abdecken müssen. Es bietet sich also an nicht nur $x$, sondern auch $a$ als Array zu behandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson distribution\n",
    "def fPoisson(x, nu_P):\n",
    "    k=np.around(x)\n",
    "    return (nu_P**k) / np.exp(nu_P) / sp.gamma(k+1.)\n",
    "\n",
    "# Likelihood function\n",
    "def Likelihood(x, a, func):\n",
    "# ->>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie nun die Likelihoodfunktion für eine steigende Zahl an Messergebnissen $L\\left(\\left\\{x_i\\right\\}|a\\right)$. Stellen Sie dafür die Likelihoodfunktion für $a$ im Intervall $[2,9]$ dar für\n",
    "* nur den ersten Messwert,\n",
    "* den ersten und den zweiten Messwert,\n",
    "* die ersten 10 Messwerte,\n",
    "* die ersten 100 Messwerte.\n",
    "\n",
    "Sie können mithilfe von *np.loadtxt(\"filename\")* die Messdaten aus dem Verzeichnis laden, indem Sie das Notebook ausführen. Sollten Sie also das Notebook von ihrem eigenen PC in der Jupyter-Umgebung des SCC-Jupyter-Servers laden oder lokal auf Ihrem Rechner arbeiten, denken Sie daran, zuerst die Datei *Geiger_Zaehler.txt* herunterzuladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#->>  your code comes here \n",
    "# load observations\n",
    "\n",
    "\n",
    "# create parameter intervall\n",
    "\n",
    "# list for desired observation numbers\n",
    "\n",
    "\n",
    "# make plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Frage: Erläutern Sie das Verhalten des Maximums der Likelihoodfunktion. Schätzen Sie den Wert des gesuchten Paramters ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "->> Antwort:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]

  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "## b) Negative Log-Likelihood\n",
    "\n",
    "In der Praxis verwendet anstelle von $L$ man die **Negative Log Likelihood (NLL)**\n",
    "\n",
    "Beachten Sie die $y$-Skala bzw. den Wertebereich der Likelihoodfunktion für die vier verschiedenen Anzahlen an Messpunkten. Für eine große Anzahl an Messpunkten nimmt die Funktion immer kleinere Werte an. Eine Logarithmierung des Ausdruck vereinfacht nicht nur die  mathematische Analyse, sondern hilft auch numerisch, da das Produkt einer großen Anzahl kleiner Wahrscheinlichkeiten die numerische Genauigkeit des Computers für Fließkommaoperationen leicht unterschreiten kann, und dies wird gelöst, indem stattdessen die effizientere Summe der natürlichen Logarithmen der Wahrscheinlichkeiten (\"Log Likelihood\") berechnet wird. Statt nach dem Maximum der Likelihoodfunktion zu suchen, wird häufig nach dem Minimum der negativen Log Likelihood (NLL) gesucht. \n",
    "\n",
    "$$ \n",
    "-\\ln\\left(L\\left(\\left\\{x_i\\right\\}|a\\right)\\right)=-\\sum_{i\\leq n}\\ln\\left(f\\left(x_i,a\\right)\\right).\n",
    "$$\n",
    "\n",
    "Wiederholen Sie den ersten Aufgabenteil mit der NLL-Methode. Implementieren Sie dazu eine neue Funktion, die die NLL ausgibt. Betrachten Sie denselben Parameterbereich, aber diesmal für \n",
    "* nur den ersten Messwert,\n",
    "* den ersten und den zweiten Messwert,\n",
    "* die ersten 10 Messwerte,\n",
    "* **alle Messwerte** statt nur 100 Messwerte.\n",
    "\n",
    "Stellen Sie die $-\\ln\\left(L\\left(\\left\\{x_i\\right\\}|a\\right)\\right)$ jeweils grafisch dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->> your code, please !\n",
    "\n",
    "# legative Log Likelihood function\n",
    "def NLL(x, params, func, *args, **kwargs):\n",
    "#->>\n",
    "\n",
    "# make plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Parameterschätzung\n",
    "\n",
    "Bestimmen Sie nun den gesuchten Parameter und schätzen Sie dessen $1\\sigma$-Konfidenzintervall ab, indem Sie die *asymmetrischen* Grenzen für die Unsicherheit angeben.\n",
    "\n",
    "Für den ersten Schritt kann die *NumPy*-Methode *np.argmin()* hilfreich sein. Sie gibt den Index des Arrayeintrags am Minimum aus. <br>\n",
    "Den zweiten Schritt erhalten Sie, indem Sie diejenigen Punkte finden, deren NLL-Wert um $1/2$ größer sind als der des Maximums. Das $1\\sigma$-Konfidenzintervall entspricht dann dem Wertebereich $[\\hat{a}-\\Delta^-,\\hat{a}+\\Delta^+]$. Die üblich Angabe für den besten Schätzwert erfolgt dann über folgende Darstellung:\n",
    "$$\\hat{a}^{+\\Delta^+}_{-\\Delta^-}.$$\n",
    "Hier eine schnelle Illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 1000)\n",
    "y = (x - 3)**2 + 0.2\n",
    "\n",
    "dots_x = [3 - 1/np.sqrt(2), 3, 3 + 1/np.sqrt(2)]\n",
    "dots_y = [0.7, 0.2, 0.7]\n",
    "\n",
    "plt.plot(x, y, 'b-', label='NLL')\n",
    "plt.hlines(0.7, 1, 5, color='green', label=r'NLL$[\\hat{a}]$+0.5')\n",
    "plt.plot(dots_x, dots_y, 'ro')\n",
    "\n",
    "colors = ['gold', 'orange', 'tomato']\n",
    "labels = [r'Unterschranke $\\hat{a}-\\Delta^-$', r'Minimum $\\hat{a}$', r'Oberschranke $\\hat{a}+\\Delta^+$']\n",
    "for i in range(3):\n",
    "    plt.vlines(dots_x[i], 0, dots_y[i], linestyle='dashed', color=colors[i], label=labels[i])\n",
    "\n",
    "plt.ylim(-0.1, 1)\n",
    "plt.xlim(1, 5)\n",
    "plt.xlabel(r'$a$')\n",
    "plt.ylabel(r'NLL $-\\ln L\\left(\\left\\{x_i\\right\\},a\\right)$')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es bietet sich an die Zwischenschritte als Funktion zu implementieren, damit sie erneut verwendet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ->> your own code\n",
    "def find_estimate(nlLH, par):\n",
    "\n",
    "\n",
    "a_best, a_left, a_right = find_estimate(NLL(obs, a, fPoisson), a)\n",
    "print(f'Der gesuchte Parameter konnte geschätzt werden zu {a_best:.3f}+{a_right:.3f}-{a_left:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
