{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ea5a6e-48f6-4301-a1f5-b13cda12a020",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Rechnernutzung in der Physik\n",
    "**Institut für Experimentelle Teilchenphysik**  \n",
    "Prof. G. Quast, Dr. Th. Chwalek  \n",
    "WS 2024/25 – Blatt 04  \n",
    "Abgabe: Mo./Di. 16./17. Dezember bzw. Di. 7. Januar / Mo. 20. Januar  \n",
    "Den Montagstermin am 23.12. lassen wir ausfallen. Stattdessen richten wir am Montag, 20. Januar, zwei Zeitfenster ein: morgens 9.45 Uhr bis 11.15 Uhr im Kl. HS A, nachmittags wie gewohnt 14.00 - 15.30 Uhr im Poolraum. Am 20. Januar können Sie die Blätter 04 und 05 abgeben. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996176e9-b18a-4efc-9ae9-9546052e9e1e",
   "metadata": {},
   "source": [
    "---\n",
    "# Aufgabe 1: Profile Likelihood <a id=\"Aufgabe1\"></a>\n",
    "---\n",
    "In dieser Aufgabe schauen Sie sich ein vielleicht bereits bekanntes Beispiel aus dem Praktikum an: Der Myon-Zerfall. Das Myon hat dieselben Eigenschaften wie das Elektron, nur ist es ca. 200 Mal schwerer. Myonen entstehen beispielsweise als Zerfallsprodukte kosmischer Strahlung und können dann am Boden z. B. durch ein praktisch zeitgleiches Signal (\"Koinzidenz\") in mehreren Lagen von Szintillationszählern (Detektoren, die bei Teilchendurchgang Licht emittieren, das mit Photondetektoren nachgewiesen werden kann) nachgewiesen werden. Dabei zerfallen sie größtenteils gemäß dem folgenden Prozess, illustriert als \"Feynman-Diagramm\", bei dem das Myon in ein Elektron, ein Elektron-Antineutrino und ein Myon-Neutrino zerfällt und ein virtuelles W-Boson als \"Kraftteilchen\" fungiert:\n",
    "\n",
    "<div style='text-align:center'>\n",
    "<img src='MuonDecay.png' width ='75%'>\n",
    "</div>\n",
    "\n",
    "Bei physikalischen Experimenten treten häufig Störparameter auf, die für das physikalische Ergebnis irrelevant sind, aber dessen Unsicherheit beeinflussen. Die Berechnung und Analyse der Profile-Likelihood für den jeweils interessierenden physikalischen Parameter ist eine einfache Möglichkeit, die durch Störparameter verursachten Unsicherheiten zu berücksichtigen.\n",
    "\n",
    "In der Datei *tau_mu.dat* finden Sie 150 Werte gemessener Lebensdauern von Myonen, die im oder in der Nähe eines Myondetektors gestoppt wurden. Die Zeitdifferenz zwischen dem Nachweis des einfallenden Myons und dem Eintreffen des Elektrons aus dem Zerfall ist die Messgröße. Bedingt durch das Messverfahren sind nur Zeiten zwischen $\\Delta t_{min}=1.0\\,\\mu$s und $\\Delta t_{max}=11.5\\,\\mu$s erfasst. Als Störparameter bei den Messungen tritt ein Untergrund aus Zufallskoinzidenzen von Signalen auf, die im Bereich von $[\\Delta t_{min},\\Delta t_{max}]$ als flach verteilt angenommen werden können.\n",
    "\n",
    "In den folgenden Teilaufgaben soll die Myonenlebensdauer $\\tau_{\\mu}$ bestimmt werden. Sie werden dabei bemerken, wie einfach das mit dem Wissen aus der Vorlesung und der vorigen Übung ist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac87c51-d806-4f06-835d-af0e75818a69",
   "metadata": {},
   "source": [
    "## a) Verteilungsdichte der Zeitdifferenzen\n",
    "\n",
    "Zunächst soll die zugrunde liegende Wahrscheinlichkeitsdichte der Messdaten erstellt werden. Aus dem Aufbau der Messung ist zu entnehmen, dass die Verteilung der gemessenen Zeitdifferenzen aus der Summe einer Gleichverteilung und einer Exponentialverteilung besteht. \n",
    "* Die **Gleichverteilung** für den Untergrund aus Zufallskoinzidenzen ist durch den relativen Anteil $f_b$ an der Gesamtanzahl gemessener Zeitdifferenz als Störparameter skaliert.\n",
    "* Die **Exponentialverteilung** für den Myonenzerfall ist charakterisiert durch die Myonenlebensdauer $\\tau_{\\mu}$ und beinhaltet die noch zu bestimmende Normierungskonstante $C_n$. Außerdem wird der Störparameter $f_b\\in[0,1]$ berücksichtigt durch den Faktor $(1-f_b)$, so dass die relativen Anteile in der Summe Eins ergeben.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{PDF}(t)=C_n(1-f_b)\\exp\\left\\{-\\frac{t}{\\tau_{\\mu}}\\right\\}+\\frac{f_b}{\\Delta t_{max}-\\Delta t_{min}}\n",
    "$$\n",
    "\n",
    "Zur Vorbereitung der Auswertung führen Sie folgende Schritte aus:\n",
    "1. Implementieren Sie eine Funktion, die die Wahrscheinlichkeitsdichte ausgibt. Beachten Sie, dass die PDF auf Eins normiert sein muss. Bestimmen Sie dazu die Normierungskonstante $C_n$.\n",
    "2. Implementieren Sie eine Funktion, die die NLL der PDF ausgibt, falls diejenige, die Sie in der [ersten Aufgabe](#Aufgabe1) geschrieben haben, nicht ausreichen sollte.\n",
    "3. Lesen Sie die Daten aus der gegebenen Datei ein und histogrammieren Sie diese, damit Sie eine grobe Vorstellung des Problems erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134606c-7dfb-4085-b9ea-0af66562d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and helper functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c30bc-a6cf-4416-8d50-cedea7a884b5",
   "metadata": {},
   "source": [
    "Wir benötigen für diese Studie wieder zwei der schon auf dem letzten Blatt verwendeten\n",
    "Funktionen zur Berechnung der negativen log-likelihood Funktion und zur Bestimmung \n",
    "des Minimums und nlL+/-0.5, die in der Zelle unten zur Verfügung gestellt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49afada-d829-4f86-8d9d-7bb4b57a7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Log Likelihood function\n",
    "def NLL(x, params, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "      calculate negative log likelihood for lists of parameter values\n",
    "\n",
    "      Args:\n",
    "        x: observations\n",
    "        params: array of parameter values\n",
    "        func: PDF\n",
    "        args, kwargs: optional parameter for PDF\n",
    "\n",
    "      Returns:\n",
    "        (array of) float: NLL of PDF given paramas array\n",
    "    \"\"\"       \n",
    "    nlLi = np.zeros(len(params))\n",
    "    for i, param in enumerate(params):\n",
    "        nlLi[i] = -np.sum(np.log(func(x, param, *args, **kwargs)))\n",
    "    \n",
    "    return nlLi\n",
    "    \n",
    "\n",
    "def find_estimator(nlLH, par):\n",
    "\n",
    "    # find minimum\n",
    "    min_ind = np.argmin(nlLH)\n",
    "\n",
    "    # find right of and left of minimum value for nll+0.5 \n",
    "    for i in range(len(nlLH) - 1):\n",
    "        if nlLH[i] >= nlLH[min_ind] + 0.5 and nlLH[i+1] < nlLH[min_ind] + 0.5:\n",
    "            left_ind = i\n",
    "        if nlLH[i] < nlLH[min_ind] + 0.5 and nlLH[i+1] >= nlLH[min_ind] + 0.5:\n",
    "            right_ind = i\n",
    "\n",
    "    # calculate results\n",
    "    param_min = par[min_ind]\n",
    "    paramd_left = np.abs(param_min - par[left_ind])\n",
    "    paramd_right = np.abs(param_min - par[right_ind])\n",
    "    \n",
    "    return param_min, paramd_left, paramd_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f4f7d-0d09-4300-b819-100d05e7fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: Implementieren Sie die pdf für den Myon-Zerfall.\n",
    "# function signature:\n",
    "#   decaypdf(t, fb=0.1, tau=2.2, dt_min=1., dt_max=11.5)\n",
    "#   agruments: \n",
    "#     t: decay times, \n",
    "#     fb: background fraction\n",
    "#     tau: mean lifetime\n",
    "#     dt_in: minmum of decay times\n",
    "#     dt_max: myximum of decay times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a403b-96ac-406b-8bba-312c38d29e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -->  to do: Laden Sie die Daten aus der Datei \"tau_mu.dat\" und plotten Sie die Daten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2864f8-49ef-4fc6-a0c5-cdbf4fbef5a7",
   "metadata": {},
   "source": [
    "## b) Bestimmung der Profile Likelihood\n",
    "\n",
    "Zur Bestimmung der Profile Likelihood wählen Sie 200 Werte $\\tau_i$ für die Lebensdauer\n",
    "$\\tau_{\\mu}$ im Intervall zwischen $1.5\\,\\mu$s und $2.9\\,\\mu$s. Minimieren Sie für jeden Wert die NLL $-\\ln L(\\Delta t;\\tau_i,f_b)$ bezüglich des Parameters $f_b$. Die Untergrundrate $f_b$ können Sie durch 200 Werte im Intervall $[0,0.3]$ wählen – dies entspricht einem kleinen Untergrundanteil von ca. 0-30%. <br>\n",
    "Stellen Sie die Profile Likelihood geeignet dar. Zeichnen Sie ebenfalls die Linie ein, die die Abschätzung des $1\\sigma$-Konfidenzintervalls zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519439e-5408-493c-8634-c086e573e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do:  Erzeugen der Profile-Likelihood für den Parameter tau,\n",
    "#   d.h. für verschiedene Werte von tau wird das Minimum bzl. des Parameters fb gesucht\n",
    "#\n",
    "#  falls Sie keine eigene Implementerierung vorsehen, können Sie die oben angegebenen \n",
    "# Funktion NLL() zur Berechnung der Likelihood für einen Array von fbkg-Werten mutzen\n",
    "\n",
    "# -> Arrays von Werten für tau und fb erzeugen\n",
    "# -> Array mit Werten der Profle-Likelihood für die tau-Werte erzeugen\n",
    "# -> Profile-Likelihood grafisch darstellen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f870f-1ad6-4b2e-a65c-cea8a583a7b5",
   "metadata": {},
   "source": [
    "## c) Parameterschätzung\n",
    "\n",
    "Bestimmen Sie als letzten Schritt \n",
    "- den bestmöglichen Schätzer für die Myonenlebensdauer $\\hat{\\tau}_{\\mu}$, \n",
    "- dessen asymmetrischen Grenzen für die Unsicherheiten $+\\Delta^+,-\\Delta^-$\n",
    "- und den bestmöglichen Schätzer für die Untergrundrate $\\hat{f}_b$ unter der Annahme $\\hat{\\tau}_{\\mu}$.\n",
    "\n",
    "Stellen Sie die histogrammierten Zeitdifferenzen, die Verteilung des Signals unter der Annahme der bestmöglichen Schätzer und alle Ergebnisse in einem Plot dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452380fe-b439-4d4c-b965-92d2c9e8cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do:  Profile-Likelihood auswerten \n",
    "#  Hinweis: Sie können die oben bereit gestellte Funktion find_estimator vom letzen\n",
    "#   Übungsblatt verwenden, wenn Sie keine weitere eigene Implementerung machen wollen.\n",
    "\n",
    "# -> besten Wert tau_best und Unsicherheitsintevall bestimmen\n",
    "# -> für tau_best den Wert passenden Wert von fb finden. \n",
    "# -> grafische Darstellung der Daten und der angepassten Modell-Kurve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191c5a4-347f-4745-be6b-872be4f54de6",
   "metadata": {},
   "source": [
    "---\n",
    "## Aufgabe 2: Anpassungen mit dem Paket *kafe2* <a id=\"Aufgabe3\"></a>\n",
    "---\n",
    "\n",
    "Zur professionellen Anpassung von Modellen an Daten benötigt man einen umfangreichen \n",
    "\"Werkzeugkasten\", um\n",
    "  - die Daten\n",
    "  - und deren Unsicherheiten:\n",
    "    -  entweder Poisson-Unsicherheiten oder \n",
    "    -  absolut und/oder\n",
    "    -  relativ für\n",
    "    Ordinate (\"y -Richtung\") und/oder Abszisse (\"x-Richtung\") sowie\n",
    "  - Korrelationen der Unsicherheiten bzw. Kovarianzmatrizen\n",
    "\n",
    "zu spezifizieren und zu verwalten und \n",
    "  - Modelle auf flexible Weise zu definieren sowie \n",
    "  - Modellparameter\n",
    "    -  zu fixieren, \n",
    "    -  auf einen bestimmten Wertebereich zu begrenzen oder \n",
    "    -  statistisch korrekt auf einen Wert innerhalb von Unsicherheiten zu begrenzen. \n",
    "\n",
    "Außerdem sollten verschiedene Optionen vorhanden sein, um das \"Abstandsmaß\"\n",
    "zwischen Modell und Daten (die Kostenfunktion) wählen zu können, also z.B. \n",
    "kleinste Quadrate-Methode oder verschiedene Varianten von Likelihood-Verfahren.\n",
    "\n",
    "\n",
    "#### Übersicht über die Aufgabenstellung  \n",
    "Zunächst knüpfen wir an die vorangegangenen Aufgaben an. Als erstes soll eine\n",
    "Likelihood-Anpassung an Daten durchgeführt werden, die einem Gauß-förmigen\n",
    "Signal über einem flachen Untergrund entsprechen (\"ungebinnter Likelkihood-Fit\").\n",
    "Sie können sich als Beispiele aus der Physik z.B. ein Gamma-Spektrum vorstellen, \n",
    "also die gemessenen Energien von Gamma-Quanten, die bei einer bestimmten Energie\n",
    "eine Anhäufung (Spektrallinie) zeigen, oder auch die relativistische invariante\n",
    "Masse der Tochterteilchen aus dem Zerfall eines Elementarteilchens (und viele, viele \n",
    "weitere Beispiele...).\n",
    "\n",
    "Als nächstes sollen diese Daten als Häufigkeitsverteilung (Histogramm) dargestellt\n",
    "und eine Likelihood-Anpassung an das Histogramm durchgeführt werden (\"gebinnter\n",
    "Likelkhood Fit).\n",
    "\n",
    "Im letzten Aufgabenteil untersuchen wir ein typisches Beispiel für die Anpassung \n",
    "von Paaren von Messwerten, für die wir einen funktionalen Zusammenhang vermuten,\n",
    "eine Strom-Spannungskennlinie. Dabei treten die oben erwähnten verschiedenen Typen\n",
    "von Unsicherheiten auf. Solche Problemstellungen kennen sie schon gut aus den\n",
    "Praktika zur klassischen Physik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b59dc2-76d5-4941-8c36-838299a88326",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### Anpassungen mit kafe2\n",
    "Das Paket `kafe2` erfüllt die oben genannten Kriterien und\n",
    "bietet ein einfaches stand-alone Tool, *kafe2go*, zur schnellen Behandlung\n",
    "vergleichsweise einfacher Probleme. Weiter gibt es Wrapper-Funktionen, die die\n",
    "Ausführung von Anpassungen mit einem Funktionsaufruf ermöglichen.  \n",
    "In dieser Aufgabe wollen wir aus Gründen der Flexibilität mit dem objekt-orientierten\n",
    "(oo-)Interface arbeiten, das eine Reihe von Klassen mit entsprechenden Methoden enthält,\n",
    "um Probleme vom oben beschriebenen Typ zu behandeln.\n",
    "\n",
    "Dies sind zum einen Klassen, die die Daten und Unsicherheiten bereit stellen:\n",
    "```python\n",
    "   UnbinnedContainer\n",
    "   HistContainer\n",
    "   XYContainer\n",
    "```\n",
    "\n",
    "Weiter gibt es dazu passende Klassen, um Anpassungen durchzuführen. \n",
    "Diese Fit-Klassen werden mit einer Instanz einer Container-Klasse und einem Fit-Modell\n",
    "instantiiert, also einer (normierten) Verteilungsdichte oder einer Modellfunktion für\n",
    "den xy-Fit. Dazu gibt es eine generische Klasse `Fit`.  \n",
    "Mit der Methode `Fit.add_error()` der Fit-Klasse können vor Ausführung der Anpassung \n",
    "verschiedene Typen von Unsicherheiten zur Kovarianzmatrix hinzugefügt werden.  \n",
    "Für Anpassungen von Modellen sind grundsätzlich Startwerte für die Parameter notwendig,\n",
    "um Lösungen in der Nähe von lokalen Minima der Kostenfunktion zu vermeiden. Dazu\n",
    "dient die Methode `Fit.set_parameter_values()`, die vor Ausführung der Anpassung aufgerufen\n",
    "werden muss. Es kann auch nötig sein, die anfängliche Schrittweite bei der Suche nach\n",
    "dem Minimum der Kostenfunkion vorzugeben, die über die anfänglich angenommenen\n",
    "Unsicherheiten der Parameter gesetzt wird. Das ist immer dann nötig ist, wenn die anfänglichen Parameterwerte nicht von der Größenordnung Eins sind. Die initialen Unsicherheiten kann man mit dem Attribut `Fit.parameter_errors` setzen.  \n",
    "Die Methoden `Fit.fix_parameter()`, `Fit.limit_parameter()` und\n",
    "`Fit.add_parameter_constraint()` erlauben es, Parameter im Fit festzuhalten, \n",
    "auf einen Wertebereich einzuschränken bzw. sie innerhalb von Unsicherheiten zu begrenzen.  \n",
    "Die Ausführung der Anpassung erfolgt mit der Methode `Fit.do_fit()`, die ein\n",
    "Python-Dictionary als Ausgabe mit allen Fit-Resultaten zurück gibt.\n",
    "Die Methode `Fit.report()` liefert einen Ausdruck der Ergebnisse.\n",
    "\n",
    "Zusätzlich gibt es Helfer-Klassen, die die grafische Darstellung, die Extraktion\n",
    "von Profile-Likelihood-Kurven oder von zweidimensionalen Konfidenzkonturen ermöglichen: \n",
    "die für alle Fit-Klassen verwendbaren, generischen Klassen `Plot` und `ContoursProfiler`. \n",
    "\n",
    "Zur Verwendung dieser Klassen schauen Sie sich die Vorlesungsbeispiele oder\n",
    "die im Unterverzeichnis *examples/* des *kafe2*-Pakets gesammelten Beispiele\n",
    "sowie ggf. die \n",
    "[*kafe2*-Dokumentation](https://kafe2.readthedocs.io/en/latest/parts/user_guide.html) an.\n",
    "\n",
    "Die typische Struktur einer Anpassung mit *kafe* unter Verwendung des\n",
    "objekt-orientierten Interface sieht so aus:\n",
    "\n",
    "```python\n",
    "# --- general example of a kafe2 fit using the oo interface\n",
    "# Importe\n",
    "\n",
    "# kafe2 Datencontainer\n",
    "from kafe2 import XYContainer, HistContainer, UnbinnedContainer\n",
    "# generische Fit-Klasse\n",
    "from kafe2 import Fit\n",
    "# Hilfsklassen\n",
    "from kafe2 import Plot, ContoursProfiler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modell definieren:\n",
    "def xy_model(x, a, b):\n",
    "    return a*x +b \n",
    "\n",
    "# Daten bereit stellen\n",
    "x_data = [1.0, 2.0, 3.0, 4.0]\n",
    "y_data = [2.3, 4.2, 7.5, 9.4]\n",
    "# absolute uncertainty for x, relative for y\n",
    "x_uabs = 0.1\n",
    "y_urel = 0.1\n",
    "\n",
    "# Daten-Container aufsetzen, z.B. \n",
    "xy_data = XYContainer(x_data, y_data)\n",
    "\n",
    "# Fit-Objekt erzeugen\n",
    "xy_fit = Fit(xy_data, xy_model)\n",
    "\n",
    "# add uncertainties here,\n",
    "#   because this is the only place also for errors depending on model \n",
    "xy_fit.add_error(axis='x', err_val = x_uabs)\n",
    "xy_fit.add_error(axis='y', err_val = y_urel, reference='model')\n",
    "\n",
    "# steer fit by setting initial values and uncertainties\n",
    "xy_fit.set_parameter_values(a=1, b=1)\n",
    "xy_fit.parameter_errors = [0.1, 0.1]\n",
    "xy_result = xy_fit.do_fit()  # perform fit\n",
    "\n",
    "# optionally print result\n",
    "xy_fit.report(asymmetric_parameter_errors=True) # use neg. log L scan to determine uncertainties\n",
    "\n",
    "# optionally, plot results\n",
    "xy_plot = Plot(xy_fit)\n",
    "xy_plot.plot(asymmetric_parameter_errors=True)\n",
    "\n",
    "# optionally, determine profile-likelihood and 2d confidence contours\n",
    "cpf = ContoursProfiler(xy_fit)\n",
    "# cpf.plot_profiles_contour_matrix\n",
    "cpf.get_profile('a')\n",
    "cpf.plot_profile('a')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Ihre eigenen Lösungen der Aufgaben unten sollten dieser Vorlage folgen. \n",
    "Sie können die Vorlage in eine code-Zelle kopieren und ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196afc90-8e38-4f92-bede-c557f0089674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# --> to do: Importe \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75639584-98a9-4e09-a099-e218484b15a0",
   "metadata": {},
   "source": [
    "## Aufgabe a) Unbinned Likelihood-Fit\n",
    "\n",
    "Eine ungebinnten Fit nutzt man immer dann, wenn die Verteilungsdichte von Daten bestimmt werden soll,\n",
    "die Anzahl an Werten aber nicht ausreicht, um sinnvoll ein Histogramm darzustellen. Diese Aufgabe \n",
    "entspricht der auf dem letzten Blatt, nur soll dieses Mal *kafe2* verwendet werden. Die Daten \n",
    "werden dazu in einen *UnbinnedContainer\" geladen, der mit einer Modellfunktion zur Initialisierung\n",
    "einer Instanz der generischen Klasse *Fit* verwendet wird, deren Methoden dann ganz analog zur \n",
    "Vorlage oben zur Ausführung der Anpassung und Ausgabe der Ergebnisse und Grafiken angewandt \n",
    "werden. \n",
    "\n",
    "Als erstes werden die Daten aus der Datei *kafe2_data.csv* in einen numpy-array geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f0e34-4a6c-4a64-afc2-7335fb681de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('kafe2_data.csv')\n",
    "#print(data)\n",
    "\n",
    "# --> to do: Erzeugung eines Histogramms der Daten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583137a4-375e-4118-8f93-fc426c5571b5",
   "metadata": {},
   "source": [
    "#### Definition einer Modell-Funktion\n",
    "\n",
    "Schreiben Sie nun eine Modellfunktion, die eine Gaußverteilung auf einem flachen Untergrund im Wertebereich\n",
    "vom Minimum bis zum Maximum der eingelesenen Daten darstellt. Achten Sie darauf, dass die Verteilungsdichte\n",
    "auf Eins normiert sein muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c8126-32f4-4550-9859-fc080473edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--> to do: Coden Sie die Modellfunktion mit der Signatur \n",
    "#   signal_plus_background(x, mu, sigma, s, min=0., max=1.)\n",
    "#   \"\"\"(normalized) pdf of a Gaussian signal on top of flat background\"\"\"\n",
    "#   x: x-Werte der Daten\n",
    "#   mu: Erwartungswert\n",
    "#   sigma: Standardabweichung\n",
    "#   s: Signalanteil an den Daten\n",
    "#   min: Minimum der X-Werte\n",
    "#   max: Maximum der x-Werte\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a1268-9866-4252-96fd-be590bafc3d8",
   "metadata": {},
   "source": [
    "Erzeugen Sie als nächstes die Objekte der benötigten Klassen und setzen Sie den Fit auf.\n",
    "Wählen Sie vernünftige Startwerte für die Parameter und fixieren Sie die Werte für *min*\n",
    "und *max* mit der Methode `Fit.fix_parameter()*. Führen Sie dann die Anpassung aus \n",
    "und erzeugen eine Ergebnis-Grafik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5f6d6-5a3b-4692-9560-fe9b05ff3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: UnbinnedContainer und Fit instantiieren, Fit ausführen, Daten und Fit plotten\n",
    "\n",
    "\"\"\"Likelihood fit to unbinned data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688f746-becb-4a52-95ee-969e9bb1a7cd",
   "metadata": {},
   "source": [
    "Als letztes erzeugen Sie eine Instanz der Klasse `Fit.ContoursProfiler` und nutzen Sie die Methode\n",
    "`Fit.ContoursProfiler.get_profile()`, um die Profile-Likelihood für den Parameter *s* zu erhalten. Die Parameter sind:\n",
    "`get_profile(parameter, low=None, high=None, sigma=None, cl=None, points=None, subtract_min=None)`\n",
    "        \n",
    "Sie können auch die Methode `Fit.ContoursProfiler.plot_profile()`verwenden, um eine grafische\n",
    "Ausgabe zu erzeugen.\n",
    "\n",
    "**Hinweis**: Bitte beachten, dass ein Wert des Parameters *s* von Null impliziert, \n",
    "dass die Paramter *mu* und *sigma* nicht definiert sind, an diesem Punkt also auch kein\n",
    "Profiling möglich ist. Die Profile-Likelihood kann also erst ab einem Wert\n",
    "*s* $~\\gtrsim~$0.02 erstellt werden. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6162334-5552-4889-9fa5-e98e95566da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do:  Profile-Likelihood für den Parameter s erzeugen und anzeigen\n",
    "\n",
    "\"\"\"Get profile likelihood from kafe2\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ff913-6082-47a0-8d4f-3d7000c0a0ca",
   "metadata": {},
   "source": [
    "Lesen Sie die Signifikanz für die Beobachtung des Gauß-förmigen Signals aus der Profil-Likelihood ab!\n",
    "\n",
    "to do:  Die Signifikanz beträgt ? Sigma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43454b-171b-4f01-85c8-77a84e2a9972",
   "metadata": {},
   "source": [
    "## Aufgabe b) Binned histogram fit\n",
    "\n",
    "Wenn die Datenmenge ausreichend groß ist, kann man die Anpassung direkt an ein Histogramm der\n",
    "Daten vornehmen. Dazu dient die Klasse *HistContainer*  mit den Parametern\n",
    "`HistContainer(n_bins=35, bin_range=(minx, maxx), fill_data=data)`.  \n",
    "\n",
    "Die Ausführung der Anpassung und die Extraktion der Profil-Likelihood funktionieren dann ganz analog \n",
    "zur vorigen Aufgabe. Vergleichen Sie die beiden Ergebnisse für den gebinnten und den ungebinnten Fit.\n",
    "Was passiert, wenn Sie sehr viele Bins verwenden, so dass am Ende nur noch null ode ein Ereignis \n",
    "in einem Bin vorhanden sind? \n",
    "\n",
    "**To do**: Benennen und erläutern Sie Unterschiede.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46a868-e81a-47e3-ac2d-19261c7d00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: HistContainer und Fit instantiieren, Fit ausführen und Profile Likelihood anzeigen\n",
    "\"\"\"Fitting a density distribution to a histogram \n",
    "\"\"\"\n",
    "\n",
    "# -> Create a histogram container from the dataset, choose number of bins wisely!\n",
    "# -> create the Fit object by specifying a density function\n",
    "# -> Optional: create a plot and show it\n",
    "\n",
    "\"\"\"Get profile likelihood from kafe2\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65aec1-4960-48a5-80f1-17c505c5cdb7",
   "metadata": {},
   "source": [
    "## Aufgabe c) Anpassung an Daten mit mehrern Typen von Unsicherheiten\n",
    "\n",
    "In diesem Aufgabenteils soll eine Anpassung unter Berücksichtigung aller für ein \n",
    "typisches Messgerät vorhandenen absoluten und relativen Unsicherheiten durchgeführt \n",
    "werden. \n",
    "Wir betrachten dazu einen Datensatz aus je 20 gemessenen Strom- und Spannungswerten,\n",
    "gemessen in den Messbereichen Spannung $U\\in[0, 2]$ V und Strom $I\\in[0, 200]$ mA.\n",
    "\n",
    "Die Unsicherheiten der Messungen ergeben sich aus den Herstellerangaben:\n",
    "- Jeder Messbereich umfasst eine Angabe von vier Stellen mit einer **absoluten\n",
    "  Unsicherheit** von **zwei in der letzten Stelle**. Werte werden vom Messgerät im\n",
    "  festen Format *x.xxx* V angezeigt;  die Unsicherheit bezieht sich auf die \n",
    "  letzte Stelle, also +/- 0.002 V. Der Strom wird im Format *xxx.x* mA angezeigt,\n",
    "  die Unsicherheit ist also 0.2 mA.\n",
    "- Alle Strom- und Spannungsmessungen unterliegen weiter einem **Untergrundrauschen**, \n",
    "  bei der Spannung **$\\pm$20 mV** und beim Strom **$\\pm$1 mA** an. \n",
    "- Zusätzlich wird eine **relative, vollständig korrelierte Unsicherheit**\n",
    "  von **$\\pm$5%** auf alle Messwerte angegeben, die von der Kalibrationsgenauigkeit \n",
    "  des Geräts herrührt. Die Bezugsgröße ist dabei der wahre Wert der Spannung bzw. des\n",
    "  Stroms, kleine Werte haben also eine kleinere absolute Unsicherheit als größere. \n",
    "  Diese Unsicherheit betrifft Messungen in identischen Messbereichen in gleicher\n",
    "  Weise und ist daher für jeweils für die Strom- und die Spannungsmessungen korreliert.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081427ec-81a5-4e7c-9fd1-c4acec931d17",
   "metadata": {},
   "source": [
    "### Aufgabe: Durchführen der Anpassung\n",
    "\n",
    "Implementieren Sie die Anpassung in *kafe2*, indem Sie \n",
    "- eine lineare Funktion als Modellfunktion für die Anpassung definieren,\n",
    "- die Messdaten aus der *csv*-Dateil korrekt einlesen und einen *kafe2.XYContainer*\n",
    "  initialisieren,\n",
    "- ein *kafe2.Fit*-Objekt erzeugen und  \n",
    "- alle beschriebenen Unsicherheiten korrekt mit Hilfe der Methode\n",
    "  *kaf2.Fit.add_error* hinzufügen.\n",
    "\n",
    "Beachten Sie, dass die Methode *add_error* für relative Unsicherheiten die \n",
    "Option *reference='data'/'model'* bietet. Im einen Fall werden die relativen \n",
    "Unsicherheiten durch die die gemessenen Daten bestimmt, im anderen Fall\n",
    "werden sie auf die im Fit jeweils aktuellen Modellwerte bezogen.\n",
    "Probieren Sie beides aus, indem Sie einfach zwei Fit-Objekte mit \n",
    "jeweils der einen oder der anderen Option aufsetzen. \n",
    "\n",
    "**Kommentieren** Sie den Unterschied zwischen den beiden Optionen zur Behandlung der \n",
    "relativen Unsicherheiten !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0046b5-5e83-4285-a6d5-f63f66a0592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: lineares Modell definieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99326dac-0ea0-4c93-b41a-e0bd33773780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: Daten aus der Datei \"StromSpannungsKennlinie.csv\" einlesen und graphisch darstellen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2f64b-c1a4-4c0f-9663-c3fc7e6695f3",
   "metadata": {},
   "source": [
    "In der folgende Code-Zelle sind die angenommenen Charakteristika des Messinstruments zusammengefasst,\n",
    "sozusagen als Python-Version des Datenblatts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12144e0-4fc3-473b-b657-af16c7c4805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- measurement device characteristics:\n",
    "# accuracy current measurement: 2000 Counts, +/-(5% + 2 digits) \n",
    "#   for measuring range 200mA \n",
    "crel_I = 0.05\n",
    "Idigits = 2\n",
    "Icounts = 2000\n",
    "Irange1 = 200.e-3\n",
    "# current display accuracy (A)\n",
    "sx = Idigits * Irange1 / Icounts  \n",
    "# noise component:delta I = 1 mA\n",
    "deltaI = 1e-3\n",
    "\n",
    "# accuracy voltage measurement: 2000 Counts, +/-(5% + 2 digits)\n",
    "#   for measuring range 2V\n",
    "crel_U = 0.05\n",
    "Udigits = 2\n",
    "Ucounts = 2000\n",
    "Urange1 = 2.\n",
    "# voltage display accuracy (V)  \n",
    "sy = Udigits * Urange1 / Ucounts\n",
    "# noise components: delta U = 20 mV\n",
    "deltaU = 20e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c0435-d925-4eda-ae6d-d6eaa69c3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do: Unsicherheiten zusammen fassen\n",
    "\n",
    "# abs, uncorr. I\n",
    "# sabsx = ...\n",
    "\n",
    "# rel, corr. I\n",
    "# crelx = ...\n",
    "\n",
    "# abs. uncorr U\n",
    "# sabsy = ...\n",
    "\n",
    "# rel. uncorr U\n",
    "# crely = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7562206-4bfe-4e22-b058-fa49918afa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> to do:  xyContainer(I,U) und Fit-Objekte erzeugen, \n",
    "#             obige Unsicherheiten hinzufügen, Fit laufen lassen und Ergebnisse plotten  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
